{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formation RNAseq CEA - juin 2023\n",
    "\n",
    "Session IFB : 5 CPU + 21 GB de RAM\n",
    "\n",
    "# Part 1: Download a public dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 0.1 - About session on IFB core cluster\n",
    "- 0.2 - Parameters to be set or modified by the user\n",
    "- 1 - Online researches for a dataset\n",
    "- 2 - Download data files with SRA Toolkit (*sra-tools*)\n",
    "- 3 - Obtaining fastq.gz files with fasterq-dump\n",
    "- 4 - Files and folders summary when leaving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Before going further**\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Caution:</b> \n",
    "Before starting the analysis, save a backup copy of this notebok : in the left-hand panel, right-click on this file and select \"Duplicate\"<br>\n",
    "You can also make backups during the analysis. Don't forget to save your notebook regularly: <kbd>Ctrl</kbd> + <kbd>S</kbd> or click on the ðŸ’¾ icon.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 0.1 - About session on IFB core cluster ##\n",
    "\n",
    "<em>loaded JupyterLab</em> : Version 3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 1 ##\n",
    "\n",
    "echo \"=== Cell launched on $(date) ===\"\n",
    "squeue -hu $USER \n",
    "\n",
    "echo \"=== Current IFB session size: Medium (4CPU, 10GB) or Large (10CPU, 50GB) ===\"\n",
    "jobid=$(squeue -hu $USER | awk '/jupyter/ {print $1}')\n",
    "sacct --format=JobID,AllocCPUS,NODELIST -j ${jobid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0.2 - Parameters to be set or modified by the user ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using a full path with a `/` at the end, **define the folder** where you want or have to work with the `gohome` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 2 ##\n",
    "\n",
    "gohome=\"/shared/projects/2312_rnaseq_cea/\" # to adjust with your project's folder\n",
    "\n",
    "echo \"=== Home root folder (stored in the variable gohome) is ===\"\n",
    "echo \"${gohome}\"\n",
    "echo \"\"\n",
    "echo \"=== Working (personal) folder tree ===\"\n",
    "tree \"${gohome}$USER\"\n",
    "echo \"=== Working directory ===\"\n",
    "echo \"${PWD}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please, precise the **maximum amount of CPU** (central processing units, cores) that programs can use.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    When working on your own project, you can specify  a 10-CPU session for example. Therefore, you could set the following value to <b>9, valid for a 10-CPU session</b>. Ideally, use 70-80% of the available CPU you system or session has.\n",
    "    Here we will be working on a 5-CPU session, so we use a value of 4.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 3 ##\n",
    "\n",
    "authorizedCPU=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last human determined variable we need is an accession list (SRR number, 1 per line) to start retrieving data.  \n",
    "Either define this variable here or later in **section 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 4 ##\n",
    "\n",
    "accesslist=\"${gohome}allData/Data/GSE158673_SRR_Acc_List.txt\"\n",
    "echo \"The reference list that could be used is $(echo ${accesslist})\"\n",
    "\n",
    "head -n 15 ${accesslist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list contains the complete dataset with the 11 samples that we want to analyse.   \n",
    "Nevertheless, as it would be too long to download and process all samples, and as it would generate too many heavy files, you will work on the first 3 samples,  and use the files that we already downloaded for the remaining samples.   \n",
    "\n",
    "Therefore, for this analysis, we will go on with a shorter **GSE158673_SRR_Acc_List-2.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 5 ##\n",
    "\n",
    "accesslist=\"${gohome}allData/Data/GSE158673_SRR_Acc_List-2.txt\"\n",
    "echo \"The reference list that will be used is $(echo ${accesslist})\"\n",
    "\n",
    "cat ${accesslist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 1 - Online search for sequencing samples ##\n",
    "\n",
    "Several cases can happen:\n",
    "- you read a wonderful paper and want to analyze the dataset they used or produced <br>\n",
    "- you have a project but lack the data (and/or money and/or sequencing platform!) to do it <br>\n",
    "- a enthusiastic PI asks you a question but you don't yet have the answer <br>\n",
    "\n",
    "For the two last options, you need to find a suitable dataset before going on.  \n",
    "\n",
    "If your datatest is already available on the server, skip this part... Unless you want to know how to do for next time ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **1.1- Find a paper dataset** <a id=\"section005\"></a>\n",
    "\n",
    "Research articles should include an identifier corresponding to the data used to obtain the published results.   \n",
    "This identifier corresponds usually to an entry in the <a href=\"https://www.ncbi.nlm.nih.gov/gds\"> <b>GEO datasets</b> </a> database.    \n",
    "\n",
    "In this course, we use the data registered with the GEO Series Number:  <a href=\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE158673\"> <b>GSEGSE158673</b> </a>   \n",
    "The page with this identifier provides many interesting info about the research project, such as experiments, protocols, related publications..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **1.2- Find a dataset suited for your biological question** <a id=\"section005\"></a>\n",
    "\n",
    "To that purpose, we can browse <a href=\"https://www.ncbi.nlm.nih.gov/gds\"> <b>GEO datasets</b> </a> with some filters. <br>\n",
    "\n",
    "\n",
    "Starting on the main page, proceed to a research with some (2 to 3, including *RNA seq*) key words about the research project you have. <br>\n",
    "Once you face the huge amount of results, add following filters (left side bar of webpage) :\n",
    "- *Organism* > *Customize* > *Browse* (Homo sapiens, Mus musculus, Rattus Norvegicus, ...) > select those you want to display > *Show*. Then click on the one or those you want\n",
    "- *Study type* > Select only *Expression Profiling by high throughput sequencing*. Back on the results page, click on the added option to set it active\n",
    "- If you still have too many options to handle, select *Tissue* in the *Attribute name* option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Then browse the results you have to find a paper that suits your project. <br>\n",
    "When you pick up one, keep record of some access references:\n",
    "<blockquote>\n",
    "GEO Series Number: GSExxxxxx <br>\n",
    "SRA related Number: SRPxxxxxx <br>\n",
    "SRP Run experiment: SRXxxxxxxx <br>\n",
    "BioProject reference: PRNJAxxxxxx\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    There is an alternative to the amercian NCBI database in Europe: <a href=\"https://www.ebi.ac.uk/ena/browser/home\">ENA (<i>European Nucleotide Archive</i>)</a> from <a href=\"https://www.ebi.ac.uk/\">EMBL-EBI</a> institute and part of the <a href=\"https://elixir-europe.org/platforms/data/core-data-resources\">Elixir Core Data resource</a>.<br>\n",
    "    Unfortunately, to the authors' knowledge, there is not any command-line tool to retrieve datafiles when a dataset is identified. So, we will use NCBI's resources for now.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **1.3 - Retrieve dataset informations directly from SRA archive**\n",
    "\n",
    "Go to the <a href='https://www.ncbi.nlm.nih.gov/Traces/study/'>SRA (Sequence Read Archive) Run Selector</a> portal from the NCBI.\n",
    "> Another option is the <a href='https://trace.ncbi.nlm.nih.gov/Traces/sra/'>SRA</a> website itself.\n",
    "\n",
    "A link to the **SRA Run Selector** is also provided at the bottom of the GEO datasets pages.\n",
    "\n",
    "Using the search bar with your SRA accession number, open the page of the dataset you choose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Down the page, you can select the samples you want among the full list. <br>\n",
    "Whether you select samples or want to take the entire dataset, download the `Metadata`and the `Accession List` from the `Select` section in the middle of the page.\n",
    "> Add an accession reference at the beginning of the file names (`SraRunTable.txt` and `SRR_Acc_List.txt` respectively) to distinguish series when you save many files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2 - Download data files with SRA Toolkit (<i>sra-tools</i>) ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is the first time you will be using **SRA-tools**, it is necessary to run vdb-config --interactive *(in a terminal, you have to press 'x' to save a basic configuration)*. This is not necessary for further usage. Below, we do it with writing the absolute path of the sra-tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 6 ##\n",
    "\n",
    "echo \"Aexyo\" | /shared/software/miniconda/envs/sra-tools-2.11.0/bin/vdb-config -i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to using sra command lines, we can retrieve the list of lines to download fastq files from [sra-explorer web interface](https://ewels.github.io/sra-explorer/) developped by Phil Ewels <a href=\"https://www.biostars.org/p/366721/#366722\"><i>as a fun little side project</i></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2.1 - Tools versions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load needed tools and display their current versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 6 ##\n",
    "\n",
    "module load sra-tools pigz\n",
    "# module load sra-tools/2.11 pigz/2.3.4 most recent version on the IFB as of 2023/03/15\n",
    "\n",
    "echo \"===== sra-tools modules =====\"\n",
    "prefetch --version\n",
    "vdb-validate --version\n",
    "fasterq-dump --version\n",
    "echo \"===== compression tool =====\"\n",
    "pigz --version\n",
    "echo \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 - Download SRA files with accession list**\n",
    "\n",
    "\n",
    "We will use **prefecth** as part of sra toolkit. It allows command line downloading of SRA, dbGaP and ADSP data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"alert alert-block alert-info\">\n",
    "    <li>\n",
    "        about sra toolkit <a href=\"https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/\">previous</a> and <a href=\"https://hpc.nih.gov/apps/sratoolkit.html\">latest releases</a>\n",
    "    </li>\n",
    "    <li>\n",
    "    another available option is to use <a href=\"https://www.biostars.org/p/366721/#366722\">sra-explorer web interface</a> to retrieve <code>wget</code> or <code>curl</code> bash command lines\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "We will dowload the ``.sra`` files (compressed ones) using the accession list we have downloaded before.  \n",
    "Please set here the file path and name if not previously done in **Parameters**'s section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 8 ##\n",
    "\n",
    "accesslist=\"${accesslist}\"\n",
    "echo \"The reference list that will be used is $(echo ${accesslist})\"\n",
    "#accesslist=\"${gohome}data/GSE158673_SRR_Acc_List-2.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this file ``accesslist`` for now on.  \n",
    "\n",
    "To see inside and know which references will be fetched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 9 ##\n",
    "\n",
    "cat \"${accesslist}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store downloaded files in the folder ``/shared/projects/2312_rnaseq_cea/$USER/Data/`` in a subfolder called ``sra``.   \n",
    "in which $USER corresponds to your user name and therefore to the folder that was created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Code cell 10 ##\n",
    "\n",
    "mkdir -p \"${gohome}$USER/Data/sra/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "``prefetch`` is verbose, we can see dates and how it goes directly into the notebook output. As it will take some time, we will eventually disconnect and loose tracks. To prevent information lost, we <a href=\"https://www.cyberciti.biz/faq/how-to-write-the-output-into-the-file-in-linux/\">export</a> and write screen lines in a text file (here called <code>logfile</code>).\n",
    "<blockquote>\n",
    "    <code>&#38;>></code> to capture both standard output and error output and append a file <br>\n",
    "    <code>|&#38;</code> to capture both standard output and error output to append a file, still diplaying information on screen <br>\n",
    "    <code>tee</code> read from standard input and write to standard output and files <br>\n",
    "    <code>-a</code> for <code>tee</code> command to append file instead of overwriting it\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to launch <code>prefetch</code> tool with this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 11 ##\n",
    "# We create the log text file\n",
    "\n",
    "logfile=\"${gohome}$USER/Data/sra-files_retrieval.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 12 ##\n",
    "\n",
    "echo \"Screen output is redirected to ${logfile}.\"\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starting by $(date)\" >> ${logfile}\n",
    "\n",
    "time for srrnum in $(cat \"${accesslist}\"); do\n",
    "\n",
    "    echo \"=== starting for ${srrnum}...\" |& tee -a ${logfile}\n",
    "    date &>> ${logfile}\n",
    "\n",
    "    prefetch -O \"${gohome}$USER/Data/sra/\" \\\n",
    "             ${srrnum} \\\n",
    "             &>> ${logfile}\n",
    "\n",
    "    echo \"... done $(date) ===\" |& tee -a ${logfile}\n",
    "\n",
    "done\n",
    "\n",
    "echo \"operation finished by $(date)\" >> ${logfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``prefetch`` options we use or you can add:\n",
    "<blockquote>\n",
    "    <code>-O</code> to specify destination folder <br>\n",
    "    <code>-t</code> to specify where the temporary files are to be written  <br>\n",
    "    <code>-c</code> to check if presents else download file (default, look into current working directory) <br>\n",
    "    <code>-f</code> to force overwrite existing files instead of fail <br>\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we have all expected files before going on.  \n",
    "``prefetch`` tool put every ``.sra`` file in a folder named by its accession number, so we will use the ``tree`` command to visualise them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 13 ##\n",
    "\n",
    "tree \"${gohome}$USER/Data/sra/\" >> ${logfile}\n",
    "tree \"${gohome}$USER/Data/sra/\" | grep \"files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have same numbers between samples and downloaded files, it's a good beginning point. Let's check there is no issue with those files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **2.3- Check sra files integrity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the tool **vdb-validate** from ``sra-tools`` to know if files matches those on web archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 14 ##\n",
    "\n",
    "logfile=\"${gohome}$USER/Data/sra-files_integrity.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 15 ##\n",
    "\n",
    "echo \"Screen output is redirected to ${logfile}\"\n",
    "\n",
    "echo \"operation starting by $(date)\" >> ${logfile}\n",
    "\n",
    "time for srrfile in $(find \"${gohome}$USER\" -name \"*.sra\" | sort); do\n",
    "\n",
    "    echo \"... working on $(basename ${srrfile}) file...\" |& tee -a ${logfile}\n",
    "    vdb-validate \"${srrfile}\" &>> ${logfile}\n",
    "                 \n",
    "done\n",
    "\n",
    "echo \"operation finished by $(date)\" >> ${logfile}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can either open ``.log`` file within a text editor (left panel, browse for file and right click on it) or display it in this notebook to read.  \n",
    "A shorter option consists in showing only lines that concern ``.sra`` files (extension with ``.`` and ``' `` either we will have comment lines):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 16 ##\n",
    "\n",
    "cat ${logfile} | grep \".sra' \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to count for lines that contains ***ok*** (each sample with 2 for ``md5`` and 4 for ``checksums``) or ***is consistent*** (1 per ``.sra`` file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 17 ##\n",
    "\n",
    "cat ${logfile} | grep \"md5 ok\" | wc -l\n",
    "echo $(( $(cat ${logfile} | grep \"checksums ok\" | wc -l) / 4))\n",
    "cat ${logfile} | grep \"is consistent\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3- Raw ``.fastq.gz`` files generation: \n",
    "\n",
    "### 3.1 - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul class=\"alert alert-block alert-info\">\n",
    "    <li>\n",
    "        about <a href=\"https://github.com/ncbi/sra-tools/wiki/08.-prefetch-and-fasterq-dump\">prefetch and fasterq-dump</a>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"https://usegalaxy.eu/\">usegalaxy.eu</a>: first section (<i>Get Data</i>), <br>workflow called <b>Faster Download and Extract Reads in FASTQ format from NCBI SRA</b>\n",
    "    </li>\n",
    "    <li>\n",
    "        about <a href=\"https://zlib.net/pigz/pigz.pdf\">pigz</a> for multithreading\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The ``.sra`` files downloaded in the previous cells are 'small' files compared to ``.fastq`` files. The idea is to download small amounts of data to avoid network issues during the process... but we can't start our analyses on them. We have to re-create raw ``.fastq`` files first. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To that purpose, **fasterq-dump** tool (derived from **fastq-dump** in previous sra-tools releases, now deprecated) works on a ``.sra`` file and decompress it in a fastq file (default, 1 per read so 2 for paired-end data, PE). <br>\n",
    "\n",
    "The default command line is: ``fasterq-dump filename.sra``.   \n",
    "It performs reads separation in 3 files (``--split-3`` option in **fastq-dump** tool) for paired-end data: 1 file per read direction for mate reads and another one for remaining unmated reads.  \n",
    "We can add some options to specify folders to be used, otherwise generated files will be written in current working directory. <br>\n",
    "<blockquote>\n",
    "    <code>--outdir</code>, to know where to find the <code>.fastq</code> files <br>\n",
    "    <code>--temp</code>, to control where temporary files are, indeed temporarily, stored (and check they are removed after :-) ) <br>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As ``.fastq`` files are quite big files, we'll add the compression step right after any ``.fastq`` files is created. The tool, called **pigz**, compresses files in the ``.gzip`` format that can be handled downstream. <br>\n",
    "This tool is based on **gzip** tool (so an anagram or an acronym for *Pigz is gzip*?). It allows to have several processes in parallel to work on a the same file... and it goes faster than **gzip** tool, even if it still takes quite some time: up to 8-9 minutes for the biggest file among the 11 samples processed here. <br>\n",
    "<blockquote>\n",
    "    <code>-p number</code> or <code>--processes number</code> to allow up to <code>number</code> compression threads (default is the number of online processors, or 8 if unknown)\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 - To obtain ``.fastq.gz`` files from ``.sra``**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ``--outdir`` in ``fasterq-dump`` command, we will place created files in following folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 18 ##\n",
    "\n",
    "outfolder=\"${gohome}$USER/Data/fastq/raw/\"\n",
    "mkdir -p \"${outfolder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remember, or set if not done in **Parameters**'s section, the number of CPU (central processing units, cores) that multithreading program `pigz` is suppose to use.  \n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Following value of <b>9 is valid for a 10-CPU session</b>. Ideally, use 70% of the CPU amount your system or session has.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 19 ##\n",
    "\n",
    "authorizedCPU=${authorizedCPU}\n",
    "#authorizedCPU=4\n",
    "\n",
    "echo \"The number of CPU available for computing is ${authorizedCPU}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be patient while running following *big loop*'s cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 20 ##\n",
    "\n",
    "logfile=\"${gohome}$USER/Data/sra-files_creation_fastqgz.log\"\n",
    "echo \"Screen output is redirected to ${logfile}.\"\n",
    "\n",
    "# as time command does not redirect output\n",
    "echo \"operation starting by $(date)\" >> ${logfile}\n",
    "\n",
    "time for srrnum in $(ls \"${gohome}$USER/Data/sra/\"); do\n",
    "    \n",
    "    echo \"========== Processing sample ${srrnum} ===========\" |& tee -a ${logfile}\n",
    "    srrfolder=\"${gohome}$USER/Data/sra/${srrnum}\"\n",
    "    fasterq-dump --outdir ${outfolder} \\\n",
    "                 --temp ${outfolder} \\\n",
    "                 ${srrfolder} \\\n",
    "                 &>> ${logfile}\n",
    "    \n",
    "    # don't assume there are 1 or 2 fastq by sample (3rd one if unmated reads)\n",
    "    for fullfile in $(ls \"${outfolder}\"*.fastq); do\n",
    "    \n",
    "        echo \"... compressing $(basename ${fullfile})...\" |& tee -a ${logfile}\n",
    "        date >> ${logfile}\n",
    "        pigz --processes ${authorizedCPU} ${fullfile}\n",
    "        date >> ${logfile}\n",
    "    done\n",
    "    \n",
    "done\n",
    "\n",
    "echo \"operation finished by $(date)\" >> ${logfile}\n",
    "ls -lh \"${outfolder}\" >> ${logfile}\n",
    "echo \"Step done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 - Files, folders and versions summary when leaving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of files in our destination folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 21 ##\n",
    "\n",
    "ls \"${outfolder}\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and check the arborescence of our folder with the Unix command `tree`.  \n",
    "<blockquote>\n",
    "    Adding <code>-L</code> option and a number allows to stop digging into the tree folder... and let the output be still readable. <br>\n",
    "    To list only directories, use option <code>-d</code>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 22 ##\n",
    "\n",
    "tree -d -L 3 \"${gohome}$USER/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know how many disk space files take (either shortest output or detailed one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 23 ##\n",
    "# disk usage \n",
    "\n",
    "du -ch -d1 \"${outfolder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 24 ##\n",
    "\n",
    "ls -lh \"${outfolder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "___\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "**Next practical session** \n",
    "\n",
    "The jupyter notebook used for the next session will be the *Pipe_02-bash_raw-data-quality.ipynb*    \n",
    "Let's retrieve it in our directory, in order to have a private copy to work on:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code cell 25 ##   \n",
    "\n",
    "cp \"${gohome}pipeline/Pipe_02-bash_raw-data-quality.ipynb\" \"${gohome}$USER/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Save executed notebook**\n",
    "\n",
    "To end the session, save your exectued notebook in your `run_notebooks' folder. Adjust the name with yours and reformat as code cell to run it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code cell 26 ##   \n",
    "#mkdir -p /shared/projects/2312_rnaseq_cea/$USER/run_notebooks\n",
    "cp /shared/projects/2312_rnaseq_cea/$USER/Pipe_01-bash_download-files.ipynb /shared/projects/2312_rnaseq_cea/$USER/run_notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we can go on to get an eye on data and check samples quality.  \n",
    "  \n",
    "**=> Next: Lecture 2 : Raw data quality** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Success:</b> Well done! You now know how to download fastq raw data files from GEO.<br>\n",
    "Don't forget to save you notebook and export a copy as an <b>html</b> file as well <br>\n",
    "- Open \"File\" in the Menu<br>\n",
    "- Select \"Export Notebook As\"<br>\n",
    "- Export notebook as HTML<br>\n",
    "- You can then open it in your browser even without being connected to the server! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Useful commands\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    \n",
    "- <kbd>CTRL</kbd>+<kbd>S</kbd> : save notebook<br>    \n",
    "- <kbd>CTRL</kbd>+<kbd>ENTER</kbd> : Run Cell<br>  \n",
    "- <kbd>SHIFT</kbd>+<kbd>ENTER</kbd> : Run Cell and Select Next<br>   \n",
    "- <kbd>ALT</kbd>+<kbd>ENTER</kbd> : Run Cell and Insert Below<br>   \n",
    "- <kbd>ESC</kbd>+<kbd>y</kbd> : Change to *Code* Cell Type<br>  \n",
    "- <kbd>ESC</kbd>+<kbd>m</kbd> : Change to *Markdown* Cell Type<br> \n",
    "- <kbd>ESC</kbd>+<kbd>r</kbd> : Change to *Raw* Cell Type<br>    \n",
    "- <kbd>ESC</kbd>+<kbd>a</kbd> : Create Cell Above<br> \n",
    "- <kbd>ESC</kbd>+<kbd>b</kbd> : Create Cell Below<br> \n",
    "\n",
    "<em>  \n",
    "To make nice html reports with markdown: <a href=\"https://dillinger.io/\" title=\"dillinger.io\">html visualization tool 1</a> or <a href=\"https://stackedit.io/app#\" title=\"stackedit.io\">html visualization tool 2</a>, <a href=\"https://www.tablesgenerator.com/markdown_tables\" title=\"tablesgenerator.com\">to draw nice tables</a>, and the <a href=\"https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd\" title=\"Ultimate guide\">Ultimate guide</a>. <br>\n",
    "Further reading on JupyterLab notebooks: <a href=\"https://jupyterlab.readthedocs.io/en/latest/user/notebook.html\" title=\"Jupyter Lab\">Jupyter Lab documentation</a>.<br>   \n",
    "</em>    \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BÃ©nÃ©dicte Noblet - 05-07 2021   \n",
    "Sandrine Caburet - 02-05 2023   \n",
    "Claire Vandiedonck - 02-06 2023  \n",
    "Maj 01/06/2023"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
